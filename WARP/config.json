{
    "WARP_args":
    {
        "dataset_name": "stanfordnlp/imdb",
        "model_name": "lvwerra/gpt2-imdb",
        "reward_model": "ChokeGM/reward_model_imdb",
        "batch_size": 32,
        "gradient_accumulation_steps": 2,
        "num_workers": 0,
        "I": 2,
        "M": 2,
        "T": 100,
        "nu": 0.5,
        "lambda": 0.5,
        "mu": 0.01,
        "truncate_range": [5, 15],
        "save_path": "WARP_saved",
        "HF_repository": "none",
        "optimizers_args":
        {
            "learning_rate": 5e-4,
            "weight_decay": 0.1
        }

    }
}