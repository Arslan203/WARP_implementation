{
    "WARP_args":
    {
        "dataset_name": "stanfordnlp/imdb",
        "model_name": "lvwerra/gpt2-imdb",
        "batch_size": 32,
        "num_workers": 0,
        "I": 2,
        "M": 2,
        "T": 100,
        "save_path": "WARP_saved",
        "HF_repository": "none",
        "optimizers_args":
        {
            "learning_rate": 0.0001,
            "weight_decay": 0.1
        }

    }
}